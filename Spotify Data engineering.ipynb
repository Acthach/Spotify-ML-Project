{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summer Data science project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduciton\n",
    "The goal of this probability and statistics project is aimed towards holistic growth of my abilities to work on a data science project from start to finish in hopes of replicating the process of a corporate job to better prepare me for the industry. The difference between this project and the projects ive worked on previously will be the emphasis on project planning, data collection, optimization, documentation and producitionization things I have previously ignored. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents.\n",
    "1. Project planning and research. \n",
    "2. Scraping data\n",
    "3. Data cleaning\n",
    "4. Exploratory analysis\n",
    "5. model building\n",
    "6. Putting model into production (producitionization)\n",
    "7. documentation. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Project planning and research.\n",
    "#### Project Ideas\n",
    "\n",
    "    1. Weightlifting\n",
    "        -Personal Record classification model (not alot of accessible data online) Can use web scraping, (openpowerlifting provides good powerlifting data.) you can add more data through research of powerlifters youtube videos(youtube api). \n",
    "        -although not big of a runner myself maybe route reccomendations through (strava api)\n",
    "    2. Music \n",
    "        -Music Reccomendation model  (spotify api)\n",
    "    3. Reading \n",
    "        -book reccomendation model For Ellie( Google Books API, Open Library API)\n",
    "    4. Video games\n",
    "        -Video game stats, Match making rank models, champion patch analysis, \n",
    "    5. any project resulting from Data from US census \n",
    "        -https://www.census.gov/data/developers/data-sets.html\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a list of activities I'm passionate about. Although each subject excites me, I found myself particularly drawn to developing a music recommendation model. This project resonates with me deeply because I frequently listen to music, and I have easy access to my own listening data through the spotify api. Additionally, the availability of APIs and online data for this area makes it a practical and engaging choice for my research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "import spotipy.util as util\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "from requests.exceptions import RequestException\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import time\n",
    "import requests.exceptions\n",
    "from spotipy.exceptions import SpotifyException\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spotify API reserach\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Coldplay  –  Hymn for the Weekend - Seeb Remix\n",
      "1 Otto Knows  –  Back Where I Belong (feat. Avicii)\n",
      "2 Calvin Harris  –  Under Control (feat. Hurts)\n",
      "3 ISOxo  –  how2fly\n",
      "4 Miguel  –  Girl With The Tattoo Enter.lewd\n",
      "5 Hozier  –  Too Sweet\n",
      "6 Franz Ferdinand  –  Take Me Out\n",
      "7 Rad Cat  –  leave it all behind\n",
      "8 MELVV  –  I'll Be There for You\n",
      "9 demotapes  –  ghost\n",
      "10 Juelz  –  Freaks & Geeks\n",
      "11 Avicii  –  SOS (feat. Aloe Blacc)\n",
      "12 Seven Lions  –  Not Even Love\n",
      "13 Da Tweekaz  –  LA DI DA\n",
      "14 Chance the Rapper  –  Buried Alive\n",
      "15 Fred again..  –  places to be\n",
      "16 Oliverse  –  Get High\n",
      "17 Iniko  –  The King's Affirmation\n",
      "18 J. Cole  –  Trae The Truth in Ibiza\n",
      "19 John Summit  –  Go Back (feat. Julia Church)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(client_id=\"400f5690f0bd413aab3a0b258e0c41f4\",\n",
    "                                               client_secret=\"03086e1b011c4cc18297e8c7c1dff61a\",\n",
    "                                               redirect_uri=\"http://localhost:7777/callback\",\n",
    "                                               scope=\"user-library-read\"))\n",
    "results = sp.current_user_saved_tracks()\n",
    "for idx, item in enumerate(results['items']):\n",
    "    track = item['track']\n",
    "    print(idx, track['artists'][0]['name'], \" – \", track['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how Spotipy reccomends we set up our API through the github. The issue with this is we need to create a new authentication for every different scope we want to call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range: short_term\n",
      "0 Under Control (feat. Hurts) // Calvin Harris\n",
      "1 Too Sweet // Hozier\n",
      "2 how2fly // ISOxo\n",
      "3 Hymn for the Weekend - Seeb Remix // Coldplay\n",
      "4 Wake Me Up // Avicii\n",
      "5 Not Even Love // Seven Lions\n",
      "6 leave it all behind // Rad Cat\n",
      "7 Back Where I Belong (feat. Avicii) // Otto Knows\n",
      "8 places to be // Fred again..\n",
      "9 SOS (feat. Aloe Blacc) // Avicii\n",
      "\n",
      "range: medium_term\n",
      "0 Dawn // Eliminate\n",
      "1 Cottage Gore // Subtronics\n",
      "2 far away - Crankdat Remix // Mark Tuan\n",
      "3 Huntin’ Wabbitz // J. Cole\n",
      "4 Better Off (Alone, Pt. III) // Alan Walker\n",
      "5 Wake Me Up // Avicii\n",
      "6 F.Y.U. // Excision\n",
      "7 Fever // J. Cole\n",
      "8 Black Out Days - Subtronics Remix // Phantogram\n",
      "9 King Of Nothing // BoyWithUke\n",
      "\n",
      "range: long_term\n",
      "0 Delilah (pull me out of this) // Fred again..\n",
      "1 Danielle (smile on my face) // Fred again..\n",
      "2 ten // Fred again..\n",
      "3 Clara (the night is dark) // Fred again..\n",
      "4 RATATA // Skrillex\n",
      "5 King Of Nothing // BoyWithUke\n",
      "6 Better Off Alone // Kai Wachi\n",
      "7 Dawn // Eliminate\n",
      "8 Cottage Gore // Subtronics\n",
      "9 TELEKINESIS (feat. SZA & Future) // Travis Scott\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(client_id=\"400f5690f0bd413aab3a0b258e0c41f4\",\n",
    "                                               client_secret=\"03086e1b011c4cc18297e8c7c1dff61a\",\n",
    "                                               redirect_uri=\"http://localhost:7777/callback\",\n",
    "                                               scope=\"user-top-read\"))\n",
    "\n",
    "ranges = ['short_term', 'medium_term', 'long_term']\n",
    "\n",
    "for sp_range in ranges:\n",
    "    print(\"range:\", sp_range)\n",
    "    results1 = sp.current_user_top_tracks(time_range=sp_range, limit=10)\n",
    "    for i, item in enumerate(results1['items']):\n",
    "        print(i, item['name'], '//', item['artists'][0]['name'])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " What we need to accomplish now is to extract different features from my personal spotify data in order to determine what characteristics im drawn towards when creating my model. Additioanlly what ive noticed is that I need to create a new authorization scope each time I went to extract different types of datas instead i can \n",
    "\n",
    " What we need to accomplish is to authenticate with the combined scope. This ensures that the client is authorized for all the required operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all necessary scopes\n",
    "scopes = [\n",
    "    'user-top-read',\n",
    "    'playlist-modify-private',\n",
    "    'playlist-modify-public'\n",
    "]\n",
    "\n",
    "scope = ' '.join(scopes)\n",
    "\n",
    "# Set up Spotify API client with multiple scopes\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(\n",
    "    client_id='400f5690f0bd413aab3a0b258e0c41f4',\n",
    "    client_secret='03086e1b011c4cc18297e8c7c1dff61a',\n",
    "    redirect_uri='http://localhost:7777/callback',\n",
    "    scope=scope\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid = '400f5690f0bd413aab3a0b258e0c41f4'\n",
    "secret = '03086e1b011c4cc18297e8c7c1dff61a'\n",
    "redirect_uri='http://localhost:7777/callback'\n",
    "scope ='user-top-read playlist-modify-private playlist-modify-public'\n",
    "\n",
    "token = util.prompt_for_user_token(scope, client_id=cid, client_secret=secret, redirect_uri=redirect_uri)\n",
    "\n",
    "if token:\n",
    "    sp = spotipy.Spotify(auth=token)\n",
    "else:\n",
    "    print(\"Can't get token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key above dosent print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting features for each song\n",
    "def fetch_audio_features(sp, df):\n",
    "    playlist = df[['track_id','track_name']] \n",
    "    index = 0\n",
    "    audio_features = []\n",
    "    \n",
    "    # Make the API request\n",
    "    while index < playlist.shape[0]:\n",
    "        audio_features += sp.audio_features(playlist.iloc[index:index + 50, 0])\n",
    "        index += 50\n",
    "    \n",
    "    # Create an empty list to feed in different charactieritcs of the tracks\n",
    "    features_list = []\n",
    "    #Create keys-values of empty lists inside nested dictionary for album\n",
    "    for features in audio_features:\n",
    "        features_list.append([features['danceability'],\n",
    "                              features['acousticness'],\n",
    "                              features['energy'], \n",
    "                              features['tempo'],\n",
    "                              features['instrumentalness'], \n",
    "                              features['loudness'],\n",
    "                              features['liveness'],\n",
    "                              features['duration_ms'],\n",
    "                              features['key'],\n",
    "                              features['valence'],\n",
    "                              features['speechiness'],\n",
    "                              features['mode']\n",
    "                             ])\n",
    "    \n",
    "    df_audio_features = pd.DataFrame(features_list, columns=['danceability', 'acousticness', 'energy','tempo', \n",
    "                                                             'instrumentalness', 'loudness', 'liveness','duration_ms', 'key',\n",
    "                                                             'valence', 'speechiness', 'mode'])\n",
    "    \n",
    "    # Create the final df, using the 'track_id' as index for future reference\n",
    "    df_playlist_audio_features = pd.concat([playlist, df_audio_features], axis=1)\n",
    "    df_playlist_audio_features.set_index('track_name', inplace=True, drop=True)\n",
    "    return df_playlist_audio_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['37i9dQZF1DXcBWIGoYBM5M',\n",
       " '37i9dQZF1DX0XUsuxWHRQd',\n",
       " '37i9dQZF1DX1lVhptIYRda',\n",
       " '37i9dQZF1DX10zKzsJ2jva',\n",
       " '37i9dQZF1DX4JAvHpjipBk',\n",
       " '37i9dQZF1DX4sWSpwq3LiO',\n",
       " '37i9dQZF1DX4SBhb3fqCJd',\n",
       " '37i9dQZF1DWXRqgorJj26U',\n",
       " '37i9dQZF1DX4dyzvuaRJ0n',\n",
       " '37i9dQZF1DXcF6B6QPhFDv',\n",
       " '37i9dQZF1DWXJfnUiYjUKT',\n",
       " '37i9dQZF1DXcRXFNfZr7Tp',\n",
       " '37i9dQZF1DX4o1oenSJRJd',\n",
       " '37i9dQZF1DXbTxeAdrVG2l',\n",
       " '37i9dQZF1DX4UtSsGT1Sbe',\n",
       " '37i9dQZF1DWTJ7xPn4vNaz',\n",
       " '37i9dQZF1DXaKIA8E7WcJj',\n",
       " '37i9dQZF1DWSV3Tk4GO2fq',\n",
       " '37i9dQZF1DWTwnEm1IYyoj',\n",
       " '37i9dQZF1DX2A29LI7xHn1']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlists = sp.user_playlists('spotify')\n",
    "spotify_playlist_ids = []\n",
    "while playlists:\n",
    "    for i, playlist in enumerate(playlists['items']):\n",
    "        spotify_playlist_ids.append(playlist['uri'][-22:])\n",
    "    if playlists['next']:       \n",
    "        playlists = sp.next(playlists)  \n",
    "    else:\n",
    "      playlists = None\n",
    "spotify_playlist_ids[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1027"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spotify_playlist_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrackIDs(playlist_id):\n",
    "    playlist = sp.user_playlist('spotify', playlist_id)\n",
    "    for item in playlist['tracks']['items'][:50]:\n",
    "        track = item.get('track')\n",
    "        if track is not None:\n",
    "            ids.append(track.get('id'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function get features of each track from track id\n",
    "def getTrackFeatures(track_id):\n",
    "  meta = sp.track(track_id)\n",
    "  features = sp.audio_features(track_id)\n",
    "\n",
    "  # meta\n",
    "  track_id = track_id\n",
    "  name = meta['name']\n",
    "  album = meta['album']['name']\n",
    "  artist = meta['album']['artists'][0]['name']\n",
    "  release_date = meta['album']['release_date']\n",
    "  length = meta['duration_ms']\n",
    "  popularity = meta['popularity']\n",
    "\n",
    "  # features\n",
    "  acousticness = features[0]['acousticness']\n",
    "  danceability = features[0]['danceability']\n",
    "  energy = features[0]['energy']\n",
    "  instrumentalness = features[0]['instrumentalness']\n",
    "  liveness = features[0]['liveness']\n",
    "  loudness = features[0]['loudness']\n",
    "  speechiness = features[0]['speechiness']\n",
    "  tempo = features[0]['tempo']\n",
    "  time_signature = features[0]['time_signature']\n",
    "\n",
    "  track = [track_id, name, album, artist, release_date, length, popularity, danceability, acousticness, energy, instrumentalness, liveness, loudness, speechiness, tempo, time_signature]\n",
    "  return track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5N3hjp1WNayUPZrA8kJmJP', '6dOtVTDdiauQNBQEDOtlAB', '6AI3ezQ4o3HUoP6Dhudph3', '0WbMK4wrZ1wFSty9F7FCgu', '2FQrifJ1N335Ljm3TjTVVf']\n"
     ]
    }
   ],
   "source": [
    "ids = []\n",
    "for x in spotify_playlist_ids[:200]:\n",
    "    getTrackIDs(x)\n",
    "\n",
    "print(ids[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9823\n"
     ]
    }
   ],
   "source": [
    "print(len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sublist 1 length: 76\n",
      "Sublist 2 length: 76\n",
      "Sublist 3 length: 76\n",
      "Sublist 4 length: 76\n",
      "Sublist 5 length: 76\n",
      "Sublist 6 length: 76\n",
      "Sublist 7 length: 76\n",
      "Sublist 8 length: 76\n",
      "Sublist 9 length: 76\n",
      "Sublist 10 length: 76\n",
      "Sublist 11 length: 76\n",
      "Sublist 12 length: 76\n",
      "Sublist 13 length: 76\n",
      "Sublist 14 length: 76\n",
      "Sublist 15 length: 76\n",
      "Sublist 16 length: 76\n",
      "Sublist 17 length: 76\n",
      "Sublist 18 length: 76\n",
      "Sublist 19 length: 76\n",
      "Sublist 20 length: 76\n",
      "Sublist 21 length: 76\n",
      "Sublist 22 length: 76\n",
      "Sublist 23 length: 76\n",
      "Sublist 24 length: 76\n",
      "Sublist 25 length: 76\n",
      "Sublist 26 length: 76\n",
      "Sublist 27 length: 76\n",
      "Sublist 28 length: 76\n",
      "Sublist 29 length: 76\n",
      "Sublist 30 length: 76\n",
      "Sublist 31 length: 76\n",
      "Sublist 32 length: 76\n",
      "Sublist 33 length: 76\n",
      "Sublist 34 length: 76\n",
      "Sublist 35 length: 76\n",
      "Sublist 36 length: 76\n",
      "Sublist 37 length: 76\n",
      "Sublist 38 length: 76\n",
      "Sublist 39 length: 76\n",
      "Sublist 40 length: 76\n",
      "Sublist 41 length: 76\n",
      "Sublist 42 length: 76\n",
      "Sublist 43 length: 76\n",
      "Sublist 44 length: 76\n",
      "Sublist 45 length: 76\n",
      "Sublist 46 length: 76\n",
      "Sublist 47 length: 76\n",
      "Sublist 48 length: 76\n",
      "Sublist 49 length: 76\n",
      "Sublist 50 length: 76\n",
      "Sublist 51 length: 76\n",
      "Sublist 52 length: 76\n",
      "Sublist 53 length: 76\n",
      "Sublist 54 length: 76\n",
      "Sublist 55 length: 76\n",
      "Sublist 56 length: 76\n",
      "Sublist 57 length: 76\n",
      "Sublist 58 length: 76\n",
      "Sublist 59 length: 76\n",
      "Sublist 60 length: 76\n",
      "Sublist 61 length: 76\n",
      "Sublist 62 length: 76\n",
      "Sublist 63 length: 76\n",
      "Sublist 64 length: 76\n",
      "Sublist 65 length: 76\n",
      "Sublist 66 length: 76\n",
      "Sublist 67 length: 76\n",
      "Sublist 68 length: 76\n",
      "Sublist 69 length: 76\n",
      "Sublist 70 length: 76\n",
      "Sublist 71 length: 76\n",
      "Sublist 72 length: 76\n",
      "Sublist 73 length: 76\n",
      "Sublist 74 length: 75\n",
      "Sublist 75 length: 75\n",
      "Sublist 76 length: 75\n",
      "Sublist 77 length: 75\n",
      "Sublist 78 length: 75\n",
      "Sublist 79 length: 75\n",
      "Sublist 80 length: 75\n",
      "Sublist 81 length: 75\n",
      "Sublist 82 length: 75\n",
      "Sublist 83 length: 75\n",
      "Sublist 84 length: 75\n",
      "Sublist 85 length: 75\n",
      "Sublist 86 length: 75\n",
      "Sublist 87 length: 75\n",
      "Sublist 88 length: 75\n",
      "Sublist 89 length: 75\n",
      "Sublist 90 length: 75\n",
      "Sublist 91 length: 75\n",
      "Sublist 92 length: 75\n",
      "Sublist 93 length: 75\n",
      "Sublist 94 length: 75\n",
      "Sublist 95 length: 75\n",
      "Sublist 96 length: 75\n",
      "Sublist 97 length: 75\n",
      "Sublist 98 length: 75\n",
      "Sublist 99 length: 75\n",
      "Sublist 100 length: 75\n",
      "Sublist 101 length: 75\n",
      "Sublist 102 length: 75\n",
      "Sublist 103 length: 75\n",
      "Sublist 104 length: 75\n",
      "Sublist 105 length: 75\n",
      "Sublist 106 length: 75\n",
      "Sublist 107 length: 75\n",
      "Sublist 108 length: 75\n",
      "Sublist 109 length: 75\n",
      "Sublist 110 length: 75\n",
      "Sublist 111 length: 75\n",
      "Sublist 112 length: 75\n",
      "Sublist 113 length: 75\n",
      "Sublist 114 length: 75\n",
      "Sublist 115 length: 75\n",
      "Sublist 116 length: 75\n",
      "Sublist 117 length: 75\n",
      "Sublist 118 length: 75\n",
      "Sublist 119 length: 75\n",
      "Sublist 120 length: 75\n",
      "Sublist 121 length: 75\n",
      "Sublist 122 length: 75\n",
      "Sublist 123 length: 75\n",
      "Sublist 124 length: 75\n",
      "Sublist 125 length: 75\n",
      "Sublist 126 length: 75\n",
      "Sublist 127 length: 75\n",
      "Sublist 128 length: 75\n",
      "Sublist 129 length: 75\n",
      "Sublist 130 length: 75\n",
      "['5N3hjp1WNayUPZrA8kJmJP', '6dOtVTDdiauQNBQEDOtlAB', '6AI3ezQ4o3HUoP6Dhudph3', '0WbMK4wrZ1wFSty9F7FCgu', '2FQrifJ1N335Ljm3TjTVVf', '6tNQ70jh4OwmPGpYy6R2o9', '4IadxL6BUymXlh8RCJJu7T', '2qSkIjg1o9h3YT9RAgYN75', '7221xIgOnuakPdLqT0F3nP', '46kspZSY3aKmwQe7O77fCC', '5AJ9hqTS2wcFQCELCFRO7A', '629DixmZGHc7ILtEntuiWE', '2GxrNKugF82CnoRFbQfzPf', '3Vr3zh0r7ALn8VLqCiRR10', '2HYFX63wP3otVIvopRS99Z', '3qhlB30KknSejmIvZZLjOD', '17phhZDn6oGtzMe56NuWvj', '2OzhQlSqBEmt7hmkYxfT6m', '6WatFBLVB0x077xWeoVc2k', '1bjeWoagtHmUKputLVyDxQ', '0Lmbke3KNVFXtoH2mMSHCw', '51eSHglvG1RJXtL3qI5trr', '2uqYupMHANxnwgeiXTZXzd', '6NjWCIYu1W8xa3HIvcIhd4', '4IFd7EVCyJsUHesBMXI8ju', '4q5YezDOIPcoLr8R81x9qy', '5uQ7de4EWjb3rkcFxyEOpu', '4xdBrk0nFZaP54vvZj0yx7', '3rUGC1vUpkDG9CZFHMur1t', '2bl81llf715VEEbAx03yvB', '331l3xABO0HMr1Kkyh2LZq', '1YsU8rW2u8z4F0pwOBQ4Ea', '7CyPwkp0oE8Ro9Dd5CUDjW', '4w2GLmK2wnioVnb5CPQeex', '7iabz12vAuVQYyekFIWJxD', '6XjDF6nds4DE2BBbagZol6', '0h3Xy4V4apMraB5NuM8U7Z', '3Pbp7cUCx4d3OAkZSCoNvn', '4ZJ4vzLQekI0WntDbanNC7', '1pymWRCuZfCd0zdiBJo0Hj', '5aIVCx5tnk0ntmdiinnYvw', '0mflMxspEfB0VbI1kyLiAv', '0Z7nGFVCLfixWctgePsRk9', '0LMwmV37RCmBO2so0szAFs', '5bi0gh89wRuH2OgjdAKFsb', '1aKvZDoLGkNMxoRYgkckZG', '3lMzT16MjAKKXF7pSZn13B', '4pkb8SbRGeHAvdb87v9rpf', '3SAga35lAPYdjj3qyfEsCF', '59xD5osEFsaNt5PXfIKUnX', '7iabz12vAuVQYyekFIWJxD', '4Na2HfNSr58chvfX69fy36', '4KWeGKChLKcnZsj3sIOSkW', '6AI3ezQ4o3HUoP6Dhudph3', '0izPpjfwsu2DuzWGqsABkT', '4IFd7EVCyJsUHesBMXI8ju', '2tudvzsrR56uom6smgOcSf', '7Mg5CBO37Rifk2RyDJ8fzd', '52eIcoLUM25zbQupAZYoFh', '28drn6tQo95MRvO0jQEo5C', '0l3raueiJ78IsmZGwo6CRm', '1wFFFzJ5EsKbBWZriAcubN', '0ZBg0OsGKgZajDgFtryiz7', '0SdBkFh6u5IHIXqlBu0NyI', '6O3WfmAQIgnLBGVzZJVS40', '0KFXE2mLTFdOKkTZEDgJPv', '0HGItm7Ox9AnHZbx26nkE4', '57wp7VFnV8X0pSVnYArGeJ', '0hKtu53OlIFXVuYkZwcn3o', '6EUcP55GlbmsmCzfL2vxtZ', '2MjXWroB9wlTG2kqv3avfS', '3w0w2T288dec0mgeZZqoNN', '3OxL6MuctgZp1e0zxoAZhH', '4nhcjelU9PidsBzUkazfZs', '2FoahzOSxJnalPA8aBUme3', '7hrFCoyWwKep7qp1lP4oga']\n",
      "['77DRzu7ERs0TX3roZcre7Q', '42VsgItocQwOQC3XWZ8JNA', '69phA1R4gmQsBFRQ3INW8C', '3eh51r6rFWAlGQRlHx9QnQ', '1yfKakY4rvI17lk20ekuRA', '16k6Mkih2WIccEjhtRmMni', '5OVxJ4th1sKz83BPspqMJ3', '0fPLCdD15xDslTFw28bTkt', '5tEaVciE2GnR28aN6W9cLS', '5NVOE8wRgmgNGTJNys871J', '0N3A0tvQ3ppZerKA8Gsztp', '4A3IuipnqFLJN9zDOTDSx8', '083HuPvgqYBLUiv82bVxwE', '2yUzr8Sr6ldG8vmHhZwTnz', '5RMTsrJkrtumtiIZjy7dL6', '6jTMRe8mJjZUrpECpUs3cT', '2OUK5td58k4BV2GvFdfdzr', '2x2olWuWXpqjoeE4bO1NFS', '0g3WQjlhCk9gcIVow4DigI', '7mOC6phfrfz3jfigg1aGsE', '0mpDXW1y4X7MlyPecWAlzJ', '2b7aNhysTRNWSiNM47UeWG', '7a4W4aqGWmEB8OGAixlVJq', '1LceL8vpL1OYTH2xfIKvqd', '1t2MQpMDtJT5VL2tAPHrGN', '65M92JpTbAdHmTQm4jGaDa', '0y5Ex8oQ8zCH5TQxHUy1Eo', '7221xIgOnuakPdLqT0F3nP', '61SRKyox0R9jCzci4JXKBS', '2ObBVRY8a2lnAkNG62u9eC', '4WtllVoPahHbtOGnLvS8Wk', '4pkb8SbRGeHAvdb87v9rpf', '7fveJ3pk1eSfxBdVkzdXZ0', '2z5t8IRRtt5vwkSzP9umJo', '7iQMm50NNwlUIRWhONZR2k', '1kMWJ16W3Yk3hyNmaM7jfQ', '6VpH2prT3NGiK5pnpG2L3J', '0mVYqxsm3ReFqAuxG9Orrk', '1hgINxfKQlJOikzd9skvC2', '2FQrifJ1N335Ljm3TjTVVf', '4rgtVCZ85aJHX0MVPM6fjw', '6GG4yyk3UATdBfTHVgI8PB', '1QvDl9tBq6PsMVE7Bf2ZOV', '73KAidtqbDftZjy8AD0H04', '0ayd4fDb6rMZl9uqCY3Hzl', '7gbGedaqoNVDJ8JU79AGgX', '6ouFl8UDdMc9zuzmzvmh7v', '4k0pqjIpfO7WV3eFUTgL9m', '2uqYupMHANxnwgeiXTZXzd', '7FKAVg9SA7QYLxdVRLnKjd', '727x6SZXGF0LfU2vi3rjaH', '0hQyFpC8af9Dj89fEYkXPG', '48X5k2vce5rXckgDAnXMsa', '6Ser4pIAKEoXok7eDJPRK7', '4Znwf3U6xJsQrj0UveLpOx', '2hNQDbZcN3vqRAuwiz7poI', '5ZLL6wYXeqg0k35ZkDRfhZ', '6w7OpHp3Y3ByHzmfQXYCRN', '76ODTQOl0JZQbhfxs6nRV9', '1KtQmheytoTI6kOM8yCowf', '1YvT4ml5LQM8ZYcLvqsAkD', '4ZJ4vzLQekI0WntDbanNC7', '5Ix11gWVeOnU2EKeP35AOO', '1osfLqL6L2iQsirRf83ded', '55a01VsdKH2OeSXLGy9wd5', '5ULNiLtUzRZIpbdHz47DkL', '2h9qRt8R214yJEBfoPAv3B', '2b98AhAxuK5i4YUHaQ7eQR', '2g6WCOlZS7mePH81Bxxa9s', '119cU5gffLzRlsEGSshPNQ', '7dyjQ4rUIHw3OI8Nl3kdJk', '4SrGX1rwNtpiTx5BLQpggt', '6tWGe6nvXFWT0KhGCXM89q', '2fKAG7MnnFDrQERDAzSztc', '5Uptvz6j1sjDKxidAcnH2L', '63pLfjK6FvcYJYMGwtHjd6']\n"
     ]
    }
   ],
   "source": [
    "# Function to split the list into n sublists\n",
    "def split_list(input_list, n):\n",
    "    k, m = divmod(len(input_list), n)\n",
    "    return [input_list[i*k + min(i, m):(i+1)*k + min(i+1, m)] for i in range(n)]\n",
    "\n",
    "# Splitting the list into 99 sublists\n",
    "sublists = split_list(ids, 130)\n",
    "\n",
    "# Checking the length of the sublists\n",
    "for i, sublist in enumerate(sublists):\n",
    "    print(f\"Sublist {i+1} length: {len(sublist)}\")\n",
    "\n",
    "# Optional: If you need the sublists as separate variables\n",
    "sublist_vars = [f'ids_{i+1}' for i in range(99)]\n",
    "for var_name, sublist in zip(sublist_vars, sublists):\n",
    "    globals()[var_name] = sublist\n",
    "\n",
    "# Example: Accessing the first sublist\n",
    "print(ids_1)\n",
    "print(ids_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issue currently i am having is when loop over track ids to get audio features for each track I am being rate limited by spotify API . my solution for this is to take my list of ids and split it into seperate list of 100 items because "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Max Retries reached\n",
      "Max Retries reached\n",
      "Max Retries reached\n",
      "Max Retries reached\n",
      "Max Retries reached\n",
      "Max Retries reached\n",
      "Max Retries reached\n",
      "Max Retries reached\n"
     ]
    }
   ],
   "source": [
    "tracks = []\n",
    "for i in range(len(ids_1)):\n",
    "    try:  \n",
    "        track = getTrackFeatures(ids[i])\n",
    "        tracks.append(track)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# create dataset\n",
    "df = pd.DataFrame(tracks, columns = ['track_id', 'name', 'album', 'artist', 'release_date', 'length', 'popularity', 'danceability', 'acousticness', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'time_signature'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after trying multipleways to get pass rate limiting including developing a backoff-retry strategy ive decided to do some reaserach on different ways to scrape this data. i found SpotiFile which is a scrip that allows users to more easily scrape spotify playlist,albums and artist. After continued research ive concluded that both SpotifyScraper and the above API scraping methods have depreciated due to new spotify developer guidelines (section 5). \"'scraping', whether manually or by automated means, or otherwise using any automated means (including bots, scrapers, and spiders), to view, access or collect information\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
